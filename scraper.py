import requests
import schedule
import time
from datetime import datetime
import csv
import os
from bs4 import BeautifulSoup

# Plik do zapisywania danych
DATA_FILE = "cme_data.csv"

# User-Agent do unikniÄ™cia blokowania przez CME
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

def save_to_csv(data):
    """Zapisuje dane do pliku CSV"""
    file_exists = os.path.isfile(DATA_FILE)
    
    try:
        with open(DATA_FILE, 'a', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=["timestamp", "prior_day_open_interest"])
            if not file_exists:
                writer.writeheader()
            writer.writerow(data)
            print(f"âœ… Dane zapisane do {DATA_FILE}")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d przy zapisywaniu: {e}")

def scrape_cme_data():
    """Zbiera dane z CME Group - Prior day open interest totals"""
    try:
        print(f"ğŸ”„ Scrapowanie CME Group ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})...")
        
        # Pobierz stronÄ™
        response = requests.get(
            "https://www.cmegroup.com/markets/energy/crude-oil/light-sweet-crude.settlements.html",
            headers=HEADERS,
            timeout=10
        )
        response.raise_for_status()
        
        # Parsuj HTML i szukaj danych
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Szukaj div z klasÄ… "totals-info col-sm-6"
        totals_info_divs = soup.find_all('div', class_='totals-info col-sm-6')
        
        prior_day_open_interest = None
        
        # PrzejdÅº przez wszystkie divs i szukaj "Prior day open interest totals"
        for div in totals_info_divs:
            label = div.find('span', class_='totals-info-label')
            if label and 'Prior day open interest totals' in label.get_text():
                value_span = div.find('span', class_='totals-info-value')
                if value_span:
                    prior_day_open_interest = value_span.get_text().strip()
                    break
        
        # Przygotuj dane
        data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "prior_day_open_interest": prior_day_open_interest if prior_day_open_interest else "N/A"
        }
        
        print(f"ğŸ“Š Prior Day Open Interest: {data['prior_day_open_interest']}")
        print("-" * 50)
        
        # Zapisz do pliku
        save_to_csv(data)
        
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas scrapowania: {e}")
        print(f"   SzczegÃ³Å‚y: {str(e)}")
        print("-" * 50)

def job():
    """Funkcja uruchamiana przez scheduler"""
    scrape_cme_data()

if __name__ == "__main__":
    print("ğŸš€ SCRAPER CME GROUP URUCHOMIONY!")
    print(f"   Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("   Strona: https://www.cmegroup.com/markets/energy/crude-oil/light-sweet-crude.settlements.html")
    print("   Dane bÄ™dÄ… zbierane co 30 minut")
    print("   Plik z danymi: cme_data.csv")
    print("="*50)
    
    # Uruchom pierwszÄ… scrapowanie od razu
    job()
    
    # Ustaw scheduler - uruchamiaj co 30 minut
    schedule.every(30).minutes.do(job)
    
    # GÅ‚Ã³wna pÄ™tla
    while True:
        schedule.run_pending()
        time.sleep(60)  # Sprawdzaj co minutÄ™
