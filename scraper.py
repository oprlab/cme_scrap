import schedule
import time
from datetime import datetime
import csv
import os
import requests

DATA_FILE = "investing_oil.csv"

# ‚ö†Ô∏è DANE MOCK - Do pobrania raz lokalnie i wklejenia tutaj
# Pobierz z: https://pl.investing.com/commodities/crude-oil
# i zmie≈Ñ warto≈õci poni≈ºej
MOCK_VOLUME = "77.626"  # ‚Üê Zmie≈Ñ tƒô warto≈õƒá na bie≈ºƒÖce dane (Wolumen)

# WEBHOOK - Zmie≈Ñ na URL twojego webhoka do bazy danych
WEBHOOK_URL = "https://twoja-domena.com/webhook"  # ‚Üê Zmie≈Ñ na rzeczywisty URL

# SUPABASE CONFIG - Zmie≈Ñ na swoje dane
SUPABASE_URL = "https://xxx.supabase.co"  # ‚Üê Zmie≈Ñ na URL projektu
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."  # ‚Üê Zmie≈Ñ na anon key

# Je≈õli zmienne ≈õrodowiskowe sƒÖ ustawione, u≈ºyj ich (Railway)
import os as os_module
SUPABASE_URL = os_module.environ.get("SUPABASE_URL", SUPABASE_URL)
SUPABASE_KEY = os_module.environ.get("SUPABASE_KEY", SUPABASE_KEY)

def save_to_csv(data):
    file_exists = os.path.isfile(DATA_FILE)
    try:
        with open(DATA_FILE, 'a', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=["timestamp", "volume"])
            if not file_exists:
                writer.writeheader()
            writer.writerow(data)
        print(f"‚úÖ Dane zapisane do {DATA_FILE}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd przy zapisywaniu: {e}")

def send_to_webhook(data):
    """Wysy≈Ça dane do Supabase"""
    try:
        headers = {
            "apikey": SUPABASE_KEY,
            "Content-Type": "application/json",
            "Prefer": "return=minimal"
        }
        
        payload = {
            "timestamp": data["timestamp"],
            "est_volume": data["est_volume"]
        }
        
        url = f"{SUPABASE_URL}/rest/v1/investing_oil"
        response = requests.post(url, json=payload, headers=headers, timeout=10)
        
        if response.status_code in [200, 201]:
            print(f"‚úÖ Dane wys≈Çane do Supabase: {response.status_code}")
        else:
            print(f"‚ö†Ô∏è Supabase zwr√≥ci≈Ç: {response.status_code}")
            print(f"   Odpowied≈∫: {response.text}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd Supabase: {e}")

def scrape_investing_data():
    """
    UWAGA: Ta wersja u≈ºywa mock danych, poniewa≈º Investing.com ≈Çaduje dane dynamicznie
    i Railway nie obs≈Çuguje przeglƒÖdarek (Playwright, Selenium itp).
    
    Aby zaktualizowaƒá dane:
    1. Otw√≥rz https://pl.investing.com/commodities/crude-oil w przeglƒÖdarce
    2. Znajd≈∫ pole "Wolumen"
    3. Skopiuj warto≈õƒá (np. 77.626)
    4. Zmie≈Ñ MOCK_VOLUME na tƒô warto≈õƒá
    5. Uruchom scraper ponownie
    """
    try:
        print(f"üîÑ Scrapowanie Investing.com ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})...")
        print(f"  üìä Wolumen: {MOCK_VOLUME} (dane mock)")
        print("-" * 50)
        
        data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "volume": MOCK_VOLUME
        }
        
        save_to_csv(data)
        send_to_webhook(data)
        
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd: {e}")
        print("-" * 50)

def job():
    scrape_investing_data()

if __name__ == "__main__":
    print("üöÄ SCRAPER INVESTING.COM URUCHOMIONY!")
    print(f"   Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("   ≈πr√≥d≈Ço: https://pl.investing.com/commodities/crude-oil")
    print("   Zbieranie: o r√≥wnych godzinach (:00 i :30)")
    print("   Tryb: MOCK (dane rƒôcznie aktualizowane)")
    print("="*50)
    
    job()
    schedule.every().hour.at(":00").do(job)  # Co godzinƒô o :00
    schedule.every().hour.at(":30").do(job)  # Co godzinƒô o :30
    
    while True:
        schedule.run_pending()
        time.sleep(60)
